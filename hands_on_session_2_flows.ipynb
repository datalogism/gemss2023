{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJ_pmgxvGur9"
   },
   "source": [
    "# Hands-on session 2 - Flow-based models\n",
    "## Generative Modeling Summer School 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEneMITS2agU"
   },
   "source": [
    "#### Instructions on how to use this notebook:\n",
    "\n",
    "This notebook is hosted on ``Google Colab``. To be able to work on it, you have to create your own copy. Go to *File* and select *Save a copy in Drive*.\n",
    "\n",
    "You can also avoid using ``Colab`` entirely, and download the notebook to run it on your own machine. If you choose this, go to *File* and select *Download .ipynb*.\n",
    "\n",
    "The advantage of using **Colab** is that you can use a GPU. You can complete this assignment with a CPU, but it will take a bit longer. Furthermore, we encourage you to train using the GPU not only for faster training but also to get experience with this setting. This includes moving models and tensors to the GPU and back. This experience is very valuable because, for various models and large datasets (like large CNNs for ImageNet, or Transformer models trained on Wikipedia), training on GPU is the only feasible way.\n",
    "\n",
    "The default ``Colab`` runtime does not have a GPU. To change this, go to *Runtime - Change runtime type*, and select *GPU* as the hardware accelerator. The GPU that you get changes according to what resources are available at the time, and its memory can go from 5GB to around 18GB if you are lucky. If you are curious, you can run the following in a code cell to check:\n",
    "\n",
    "```sh\n",
    "!nvidia-smi\n",
    "```\n",
    "\n",
    "Note that despite the name, ``Google Colab`` does not support collaborative work without issues. When two or more people edit the notebook concurrently, only one version will be saved. You can choose to do group programming with one person sharing the screen with the others or make multiple copies of the notebook to work concurrently.\n",
    "\n",
    "**Submission:** Please bring your (partial) solution to the hands-on session. Then you can discuss it with the intructors and your colleagues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lBgoJIpdLI2Y"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tsdc7fDp40rQ"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this assignment, we are going to implement a Flow-based Model (flows for short). A flow-based model is a likelihood-based deep generative model that is parameterized by invertible neural networks and utilizes the change-of-variable formula. The idea of using flows was presented in multiple papers, e.g.:\n",
    "- [Dinh, Laurent, Jascha Sohl-Dickstein, and Samy Bengio. \"Density estimation using real nvp.\" arXiv preprint arXiv:1605.08803 (2016).](https://arxiv.org/abs/1605.08803)\n",
    "- [Kingma, Durk P., and Prafulla Dhariwal. \"Glow: Generative flow with invertible 1x1 convolutions.\" Advances in neural information processing systems 31 (2018).](https://proceedings.neurips.cc/paper/2018/hash/d139db6a236200b21cc7f752979132d0-Abstract.html)\n",
    "\n",
    "You can read more about ARMs in Chapter 3 of the following book:\n",
    "- [Tomczak, J.M., \"Deep Generative Modeling\", Springer, 2022](https://link.springer.com/book/10.1007/978-3-030-93158-2)\n",
    "\n",
    "In particular, the goals of this assignment are the following:\n",
    "\n",
    "- Understand how flows are formulated\n",
    "- Implement flows using PyTorch\n",
    "- Train and evaluate a model for image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvsuVNczG6pP"
   },
   "source": [
    "### Theory behind flows\n",
    "\n",
    "Flows are probabilistic models that utilize the change-of-variable formula:\n",
    "$$\n",
    "p(\\mathbf{x}) = \\pi(\\mathbf{z} = f^{-1}(\\mathbf{x}))\\ |\\mathbf{J}_{f}(\\mathbf{x})|^{-1} ,\n",
    "$$\n",
    "where $\\pi(\\cdot)$ is the *base* distribution (e.g., standard Gaussian), and $\\mathbf{J}_{f}(\\mathbf{x})$ is the Jacobian matrix\n",
    "\n",
    "As a result, we can calculate the likelihood function explicitly. However, to do so, we need to pick such transformations $f$ that fulfill two requirements:\n",
    "\n",
    "- they are **invertible**;\n",
    "- the Jacobian matrix for them is **easily computable**.\n",
    "\n",
    "The first successful implementation of $f$ that fulfills both requirements was RealNVP parameterized by coupling layers (Dinh et al., 2016)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suzhlbWqxtD9"
   },
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BjxkigYLxpB7"
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE!\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cm23hRm6CqGh"
   },
   "outputs": [],
   "source": [
    "# Check if GPU is available and determine the device\n",
    "if torch.cuda.is_available():\n",
    "  device = 'cuda'\n",
    "else:\n",
    "  device = 'cpu'\n",
    "\n",
    "print(f'The available device is {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81CxONpmMulC"
   },
   "outputs": [],
   "source": [
    "# mount drive: WE NEED IT FOR SAVING IMAGES!\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OoPb92zNM4UY"
   },
   "outputs": [],
   "source": [
    "# PLEASE CHANGE IT TO YOUR OWN GOOGLE DRIVE!\n",
    "images_dir = '/content/gdrive/My Drive/Colab Notebooks/Results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3zs31tOyCmq"
   },
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF0agzL7tDHK"
   },
   "source": [
    "Let us define some useful log-distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIBNVRNJtHSd"
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE\n",
    "PI = torch.from_numpy(np.asarray(np.pi))\n",
    "EPS = 1.e-5\n",
    "\n",
    "\n",
    "def log_categorical(x, p, num_classes=256, reduction=None, dim=None):\n",
    "    x_one_hot = F.one_hot(x.long(), num_classes=num_classes)\n",
    "    log_p = x_one_hot * torch.log(torch.clamp(p, EPS, 1. - EPS))\n",
    "    if reduction == 'mean':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "\n",
    "def log_bernoulli(x, p, reduction=None, dim=None):\n",
    "    pp = torch.clamp(p, EPS, 1. - EPS)\n",
    "    log_p = x * torch.log(pp) + (1. - x) * torch.log(1. - pp)\n",
    "    if reduction == 'mean':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "\n",
    "def log_normal_diag(x, mu, log_var, reduction=None, dim=None):\n",
    "    D = x.shape[1]\n",
    "    log_p = -0.5 * D * torch.log(2. * PI) - 0.5 * log_var - 0.5 * torch.exp(-log_var) * (x - mu)**2.\n",
    "    if reduction == 'mean':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "\n",
    "def log_standard_normal(x, reduction=None, dim=None):\n",
    "    D = x.shape[1]\n",
    "    log_p = -0.5 * D * torch.log(2. * PI) - 0.5 * x**2.\n",
    "    if reduction == 'mean':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2LLOs0kn7iw"
   },
   "source": [
    "## Implementing flows\n",
    "\n",
    "The goal of this assignment is to implement one class:\n",
    "- `RealNVP`: this class implements flows using coupling layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhNTy5mn0XDT"
   },
   "source": [
    "### RealNVP\n",
    "\n",
    "The RealNVP is parameterized by coupling layer and allows efficient calculating of the Jacobian-determinant. Please remember that we must operate on continuous variables, thus, we must pick a proper base distribution (e.g., Gaussian)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vTmKHwrpUVa"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "# NOTE: The class must containt the following functions: \n",
    "# (i) sample\n",
    "# (ii) log_prob\n",
    "# (iii) log_base (i.e., log \\pi(z))\n",
    "# (iv) the coupling layer \n",
    "# (v) the invertible transformation f (i.e., a composition of coupling layers and permutation layers)\n",
    "\n",
    "class RealNVP(nn.Module):\n",
    "    def __init__(self, ): # ADD APPROPRIATE ATTRIBUTES\n",
    "        super(RealNVP, self).__init__()\n",
    "        \n",
    "        # FILL IN\n",
    "        pass\n",
    "\n",
    "    def log_base(self, x):\n",
    "        # FILL IN\n",
    "        # output: the probability \\pi(f^-1(x))\n",
    "        pass\n",
    "    \n",
    "    def sample_base(self, batch_size=32):\n",
    "        # FILL IN\n",
    "        # output: a sample from \\pi(z)\n",
    "        pass\n",
    "\n",
    "    def coupling(self, x, index, forward=True):\n",
    "        # FILL IN\n",
    "        # this is the coupling layer\n",
    "        pass\n",
    "\n",
    "    def permute(self, x):\n",
    "        return x.flip(1)\n",
    "\n",
    "    def f(self, x, forward=True):\n",
    "        # FILL IN\n",
    "        # HINT: the `forward` flag determines the direction (True: x->z, False: z->x)\n",
    "        pass\n",
    "\n",
    "    def sample(self, batchSize):\n",
    "        # FILL IN\n",
    "        # output: a sample from p(x)\n",
    "        # HINT: the sampling process is two-step: (i) z ~ \\pi(z), (ii) x = f(z, forward=False)\n",
    "        pass\n",
    "\n",
    "    def forward(self, x, reduction='avg'):\n",
    "        # FILL IN\n",
    "        # output: the log-probability that is either averaged or summed (VERY IMPORTANT!)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xjbNkNL01DP"
   },
   "source": [
    "Please answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjDvPaBj04cA"
   },
   "source": [
    "#### Question 1\n",
    "\n",
    "Please explain how coupling layers work and why we need permutation layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLZEzmGI1Ok-"
   },
   "source": [
    "ANSWER: [Please fill in]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhbWamId1eGt"
   },
   "source": [
    "#### Question 2\n",
    "\n",
    "Please explain how one can sample from the distribution chosen by you. Please be specific and formal (i.e., provide mathematical formulae)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgbEJm8FAuze"
   },
   "source": [
    "ANSWER: [Please fill in]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaJgXPYyAmeJ"
   },
   "source": [
    "#### Question 3\n",
    "\n",
    "Please explain why flows calculate the exact likelihood function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THYyO-G7AkSQ"
   },
   "source": [
    "ANSWER: [Please fill in]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLhgze7DA4yx"
   },
   "source": [
    "### Evaluation and training functions\n",
    "\n",
    "**Please DO NOT remove or modify them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9Dr3a6lqJ0W"
   },
   "outputs": [],
   "source": [
    "# ==========DO NOT REMOVE==========\n",
    "\n",
    "def evaluation(test_loader, name=None, model_best=None, epoch=None):\n",
    "    # EVALUATION\n",
    "    if model_best is None:\n",
    "        # load best performing model\n",
    "        model_best = torch.load(name + '.model')\n",
    "\n",
    "    model_best.eval()\n",
    "    loss = 0.\n",
    "    N = 0.\n",
    "    for indx_batch, (test_batch, _) in enumerate(test_loader):\n",
    "        test_batch = test_batch.to(device)\n",
    "        loss_t = model_best.forward(test_batch, reduction='sum')\n",
    "        loss = loss + loss_t.item()\n",
    "        N = N + test_batch.shape[0]\n",
    "    loss = loss / N\n",
    "\n",
    "    if epoch is None:\n",
    "        print(f'FINAL LOSS: nll={loss}')\n",
    "    else:\n",
    "        print(f'Epoch: {epoch}, val nll={loss}')\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def samples_real(name, test_loader, shape=(28,28)):\n",
    "    # real images-------\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x, _ = next(iter(test_loader))\n",
    "    x = x.to('cpu').detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], shape)\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name+'_real_images.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def samples_generated(name, data_loader, shape=(28,28), extra_name=''):\n",
    "    x, _ = next(iter(data_loader))\n",
    "    x = x.to('cpu').detach().numpy()\n",
    "\n",
    "    # generations-------\n",
    "    model_best = torch.load(name + '.model')\n",
    "    model_best.eval()\n",
    "\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = model_best.sample(num_x * num_y)\n",
    "    x = x.to('cpu').detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], shape)\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name + '_generated_images' + extra_name + '.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_curve(name, nll_val):\n",
    "    plt.plot(np.arange(len(nll_val)), nll_val, linewidth='3')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('nll')\n",
    "    plt.savefig(name + '_nll_val_curve.pdf', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ABgMeG0qFAP"
   },
   "outputs": [],
   "source": [
    "# ==========DO NOT REMOVE==========\n",
    "\n",
    "def training(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader, shape=(28,28)):\n",
    "    nll_val = []\n",
    "    best_nll = 1000.\n",
    "    patience = 0\n",
    "\n",
    "    # Main loop\n",
    "    for e in range(num_epochs):\n",
    "        # TRAINING\n",
    "        model.train()\n",
    "        for indx_batch, (batch, _) in enumerate(training_loader):\n",
    "            batch = batch.to(device)\n",
    "            loss = model.forward(batch, reduction='mean')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        loss_val = evaluation(val_loader, model_best=model, epoch=e)\n",
    "        nll_val.append(loss_val)  # save for plotting\n",
    "\n",
    "        if e == 0:\n",
    "            print('saved!')\n",
    "            torch.save(model, name + '.model')\n",
    "            best_nll = loss_val\n",
    "        else:\n",
    "            if loss_val < best_nll:\n",
    "                print('saved!')\n",
    "                torch.save(model, name + '.model')\n",
    "                best_nll = loss_val\n",
    "                patience = 0\n",
    "\n",
    "                samples_generated(name, val_loader, shape=shape, extra_name=\"_epoch_\" + str(e))\n",
    "            else:\n",
    "                patience = patience + 1\n",
    "\n",
    "        if patience > max_patience:\n",
    "            break\n",
    "\n",
    "    nll_val = np.asarray(nll_val)\n",
    "\n",
    "    return nll_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWr8N2u2qNTu"
   },
   "source": [
    "### Setup\n",
    "\n",
    "**NOTE: *Please comment your code! Especially if you introduce any new variables (e.g., hyperparameters).***\n",
    "\n",
    "In the following cells, we define `transforms` for the dataset. Next, we initialize the data, a directory for results and some fixed hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFTE5jtYpxDV"
   },
   "outputs": [],
   "source": [
    "# PLEASE DEFINE APPROPRIATE TRANFORMS FOR THE DATASET\n",
    "# (If you don't see any need to do that, then you can skip this cell)\n",
    "# HINT: Please prepare your data accordingly to your chosen distribution in the decoder \n",
    "transforms_train = torchvision.transforms.Compose( #FILL IN\n",
    "                                                  )\n",
    "\n",
    "transforms_test = torchvision.transforms.Compose( #FILL IN\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SDcOBbGCM8z"
   },
   "source": [
    "Please do not modify the code in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UXHitzrYqNhY"
   },
   "outputs": [],
   "source": [
    "# ==========DO NOT REMOVE==========\n",
    "#-dataset\n",
    "dataset = MNIST('/files/', train=True, download=True,\n",
    "                      transform=transforms_train\n",
    "                )\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [50000, 10000], generator=torch.Generator().manual_seed(14))\n",
    "\n",
    "test_dataset = MNIST('/files/', train=False, download=True,\n",
    "                      transform=transforms_test\n",
    "                     )\n",
    "#-dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#-creating a dir for saving results\n",
    "name = 'realnvp'\n",
    "result_dir = images_dir + 'results/' + name + '/'\n",
    "if not(os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)\n",
    "\n",
    "#-hyperparams (please do not modify them!)\n",
    "num_epochs = 1000 # max. number of epochs\n",
    "max_patience = 20 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmKDXMI0B231"
   },
   "source": [
    "In the next cell, please initialize the model. Please remember about commenting your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b73aaBDxqSYb"
   },
   "outputs": [],
   "source": [
    "# BASIC HYPERPARAMETERS\n",
    "D = 784   # input dimension\n",
    "\n",
    "# model definition\n",
    "# YOUR CODE COMES HERE:\n",
    "# FILL IN ANY OTHER HYPERPARAMS YOU WANT TO USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N5kdnqbiSDmq"
   },
   "outputs": [],
   "source": [
    "# INIT YOUR VAE (PLEASE CALL IT model)\n",
    "# AN EXAMPLE: model = RealNVP(...)\n",
    "\n",
    "# FILL IN\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iC8AkWt4CURT"
   },
   "source": [
    "Please initialize the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3nTSDe7ql08"
   },
   "outputs": [],
   "source": [
    "# PLEASE DEFINE YOUR OPTIMIZER\n",
    "lr = 1e-3 # learning rate (PLEASE CHANGE IT AS YOU WISH!)\n",
    "optimizer = torch.optim.Adamax([p for p in model.parameters() if p.requires_grad == True], lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79odxtRjCaix"
   },
   "source": [
    "#### Question 4\n",
    "\n",
    "Please explain the choice of the optimizer, and comment on the choice of the hyperparameters (e.g., the learing reate value)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEjOlYN9Ft_B"
   },
   "source": [
    "ANSWER: [Please fill in]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5GrzUcHFweG"
   },
   "source": [
    "### Training and final evaluation\n",
    "\n",
    "In the following two cells, we run the training and the final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VD7WuY6bqnBK"
   },
   "outputs": [],
   "source": [
    "# ==========DO NOT REMOVE OR MODIFY==========\n",
    "# Training procedure\n",
    "nll_val = training(name=result_dir + name, max_patience=max_patience, \n",
    "                   num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
    "                   training_loader=train_loader, val_loader=val_loader,\n",
    "                   shape=(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JAuMt9_wquOI"
   },
   "outputs": [],
   "source": [
    "# ==========DO NOT REMOVE OR MODIFY==========\n",
    "# Final evaluation\n",
    "test_loss = evaluation(name=result_dir + name, test_loader=test_loader)\n",
    "f = open(result_dir + name + '_test_loss.txt', \"w\")\n",
    "f.write(str(test_loss))\n",
    "f.close()\n",
    "\n",
    "samples_real(result_dir + name, test_loader)\n",
    "samples_generated(result_dir + name, test_loader, extra_name='_FINAL')\n",
    "\n",
    "plot_curve(result_dir + name, nll_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaBwGtSJF8ag"
   },
   "source": [
    "### Results and discussion\n",
    "\n",
    "After a successful training of your model, we would like to ask you to present your data and analyze it. Please answer the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4WZkoiHFyZm"
   },
   "source": [
    "#### Question 5\n",
    "\n",
    "Please select the real data, and the final generated data and include them in this report. Please comment on the following:\n",
    "- Do you think the model was trained properly by looking at the generations? Please motivate your answer well.\n",
    "- Compared to the previous assignment, could you say whether this model works better (or worse)? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8yQ2T9GIuvc"
   },
   "source": [
    "ANSWER: [Please fill in]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmyH318fIwc9"
   },
   "source": [
    "#### Question 6\n",
    "\n",
    "Please include the plot of the likelihood function. Please comment on the following:\n",
    "- Is the training of your RealNVP stable or unstable? Why?\n",
    "- What is the influence of the optimizer on your model? Do the hyperparameter values of the optimizer important and how do they influence the training? Motivate well your answer (e.g., run the script with more than one learning rate and present two plots here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-10GAVZtKTj2"
   },
   "source": [
    "ANSWER: [Please fill in]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1C6CaZsSdXdc5fONOVrJy5iYKzr2DIg9j",
     "timestamp": 1607008727578
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
